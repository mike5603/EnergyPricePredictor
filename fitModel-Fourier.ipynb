{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dayAhead = pd.read_pickle('./dayahead.pkl')\n",
    "realTime = pd.read_pickle('./realtime.pkl')\n",
    "capacity = pd.read_pickle('./Power_Plant_Capacities.pkl')\n",
    "weather = pd.read_pickle('./weather.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "def MonthToString(month):\n",
    "    return calendar.month_name[month]\n",
    "Real_Time = realTime.to_frame()\n",
    "Real_Time['Day of Month'] = Real_Time.index.get_level_values('date').day\n",
    "Real_Time['Month'] = Real_Time.index.get_level_values('date').month\n",
    "Real_Time['Year'] = Real_Time.index.get_level_values('date').year\n",
    "Real_Time['Day of Week'] = Real_Time.index.get_level_values('date').weekday\n",
    "DOW = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "Real_Time['Day Of Week String'] = Real_Time['Day of Week'].map(DOW)\n",
    "Real_Time['Month Name'] = Real_Time['Month'].map(MonthToString)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "weather.index = pd.to_datetime(weather.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_Time_Weather = Real_Time.reset_index().merge(weather,left_on='date',right_on='date').set_index(['prop','date']).loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_Time_All = Real_Time_Weather.reset_index().merge(capacity,left_on=['Month','Year'],right_on=['Month','Year']).set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_Time_All.to_pickle('realtime_combined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Real_Time_All['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>Day Of Week String</th>\n",
       "      <th>Month Name</th>\n",
       "      <th>Redding AWND</th>\n",
       "      <th>Redding PRCP</th>\n",
       "      <th>Redding TAVG</th>\n",
       "      <th>Redding TMAX</th>\n",
       "      <th>Redding TMIN</th>\n",
       "      <th>Sacremento AWND</th>\n",
       "      <th>Sacremento PRCP</th>\n",
       "      <th>...</th>\n",
       "      <th>Los Angeles TMAX</th>\n",
       "      <th>Los Angeles TMIN</th>\n",
       "      <th>Hydro Capacity</th>\n",
       "      <th>Solar Capacity</th>\n",
       "      <th>Gas Capacity</th>\n",
       "      <th>Wind Capacity</th>\n",
       "      <th>Geothermal Capacity</th>\n",
       "      <th>Nuclear Capacity</th>\n",
       "      <th>Coal Capacity</th>\n",
       "      <th>Biomass Capacity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>NP15</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>11533.56</td>\n",
       "      <td>44368.67</td>\n",
       "      <td>5989.19</td>\n",
       "      <td>2758.75</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1092.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>SP15</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>11533.56</td>\n",
       "      <td>44368.67</td>\n",
       "      <td>5989.19</td>\n",
       "      <td>2758.75</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1092.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>ZP26</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>11533.56</td>\n",
       "      <td>44368.67</td>\n",
       "      <td>5989.19</td>\n",
       "      <td>2758.75</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1092.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>PGAE</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>11533.56</td>\n",
       "      <td>44368.67</td>\n",
       "      <td>5989.19</td>\n",
       "      <td>2758.75</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1092.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>SCE</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>January</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>11533.56</td>\n",
       "      <td>44368.67</td>\n",
       "      <td>5989.19</td>\n",
       "      <td>2758.75</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1092.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>ZP26</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>12464.25</td>\n",
       "      <td>44591.65</td>\n",
       "      <td>6301.60</td>\n",
       "      <td>2795.15</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1099.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>PGAE</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>12464.25</td>\n",
       "      <td>44591.65</td>\n",
       "      <td>6301.60</td>\n",
       "      <td>2795.15</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1099.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>SCE</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>12464.25</td>\n",
       "      <td>44591.65</td>\n",
       "      <td>6301.60</td>\n",
       "      <td>2795.15</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1099.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>SDGE</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>12464.25</td>\n",
       "      <td>44591.65</td>\n",
       "      <td>6301.60</td>\n",
       "      <td>2795.15</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1099.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>VEA</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15565.39</td>\n",
       "      <td>12464.25</td>\n",
       "      <td>44591.65</td>\n",
       "      <td>6301.60</td>\n",
       "      <td>2795.15</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1898.3</td>\n",
       "      <td>1099.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4739 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           region Day Of Week String Month Name  Redding AWND  Redding PRCP  \\\n",
       "date                                                                          \n",
       "2017-01-01   NP15             Sunday    January           6.5           0.0   \n",
       "2017-01-01   SP15             Sunday    January           6.5           0.0   \n",
       "2017-01-01   ZP26             Sunday    January           6.5           0.0   \n",
       "2017-01-01   PGAE             Sunday    January           6.5           0.0   \n",
       "2017-01-01    SCE             Sunday    January           6.5           0.0   \n",
       "...           ...                ...        ...           ...           ...   \n",
       "2018-12-31   ZP26             Monday   December          12.3           0.0   \n",
       "2018-12-31   PGAE             Monday   December          12.3           0.0   \n",
       "2018-12-31    SCE             Monday   December          12.3           0.0   \n",
       "2018-12-31   SDGE             Monday   December          12.3           0.0   \n",
       "2018-12-31    VEA             Monday   December          12.3           0.0   \n",
       "\n",
       "            Redding TAVG  Redding TMAX  Redding TMIN  Sacremento AWND  \\\n",
       "date                                                                    \n",
       "2017-01-01          44.0          52.0          33.0              7.6   \n",
       "2017-01-01          44.0          52.0          33.0              7.6   \n",
       "2017-01-01          44.0          52.0          33.0              7.6   \n",
       "2017-01-01          44.0          52.0          33.0              7.6   \n",
       "2017-01-01          44.0          52.0          33.0              7.6   \n",
       "...                  ...           ...           ...              ...   \n",
       "2018-12-31          47.0          55.0          41.0             16.3   \n",
       "2018-12-31          47.0          55.0          41.0             16.3   \n",
       "2018-12-31          47.0          55.0          41.0             16.3   \n",
       "2018-12-31          47.0          55.0          41.0             16.3   \n",
       "2018-12-31          47.0          55.0          41.0             16.3   \n",
       "\n",
       "            Sacremento PRCP  ...  Los Angeles TMAX  Los Angeles TMIN  \\\n",
       "date                         ...                                       \n",
       "2017-01-01              0.0  ...              58.0              42.0   \n",
       "2017-01-01              0.0  ...              58.0              42.0   \n",
       "2017-01-01              0.0  ...              58.0              42.0   \n",
       "2017-01-01              0.0  ...              58.0              42.0   \n",
       "2017-01-01              0.0  ...              58.0              42.0   \n",
       "...                     ...  ...               ...               ...   \n",
       "2018-12-31              0.0  ...              65.0              46.0   \n",
       "2018-12-31              0.0  ...              65.0              46.0   \n",
       "2018-12-31              0.0  ...              65.0              46.0   \n",
       "2018-12-31              0.0  ...              65.0              46.0   \n",
       "2018-12-31              0.0  ...              65.0              46.0   \n",
       "\n",
       "            Hydro Capacity  Solar Capacity  Gas Capacity  Wind Capacity  \\\n",
       "date                                                                      \n",
       "2017-01-01        15565.39        11533.56      44368.67        5989.19   \n",
       "2017-01-01        15565.39        11533.56      44368.67        5989.19   \n",
       "2017-01-01        15565.39        11533.56      44368.67        5989.19   \n",
       "2017-01-01        15565.39        11533.56      44368.67        5989.19   \n",
       "2017-01-01        15565.39        11533.56      44368.67        5989.19   \n",
       "...                    ...             ...           ...            ...   \n",
       "2018-12-31        15565.39        12464.25      44591.65        6301.60   \n",
       "2018-12-31        15565.39        12464.25      44591.65        6301.60   \n",
       "2018-12-31        15565.39        12464.25      44591.65        6301.60   \n",
       "2018-12-31        15565.39        12464.25      44591.65        6301.60   \n",
       "2018-12-31        15565.39        12464.25      44591.65        6301.60   \n",
       "\n",
       "            Geothermal Capacity  Nuclear Capacity  Coal Capacity  \\\n",
       "date                                                               \n",
       "2017-01-01              2758.75            2393.0         1898.3   \n",
       "2017-01-01              2758.75            2393.0         1898.3   \n",
       "2017-01-01              2758.75            2393.0         1898.3   \n",
       "2017-01-01              2758.75            2393.0         1898.3   \n",
       "2017-01-01              2758.75            2393.0         1898.3   \n",
       "...                         ...               ...            ...   \n",
       "2018-12-31              2795.15            2393.0         1898.3   \n",
       "2018-12-31              2795.15            2393.0         1898.3   \n",
       "2018-12-31              2795.15            2393.0         1898.3   \n",
       "2018-12-31              2795.15            2393.0         1898.3   \n",
       "2018-12-31              2795.15            2393.0         1898.3   \n",
       "\n",
       "            Biomass Capacity  \n",
       "date                          \n",
       "2017-01-01           1092.09  \n",
       "2017-01-01           1092.09  \n",
       "2017-01-01           1092.09  \n",
       "2017-01-01           1092.09  \n",
       "2017-01-01           1092.09  \n",
       "...                      ...  \n",
       "2018-12-31           1099.86  \n",
       "2018-12-31           1099.86  \n",
       "2018-12-31           1099.86  \n",
       "2018-12-31           1099.86  \n",
       "2018-12-31           1099.86  \n",
       "\n",
       "[4739 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Real_Time_All.drop(['total','Day of Month','Month','Year','Day of Week'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['region','Day Of Week String','Month Name']\n",
    "scale = [x for x in list(X.columns) if x not in one_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalePipe = Pipeline([('impute',KNNImputer(missing_values=np.nan)),('scale',StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Column_Transformer = ColumnTransformer(transformers=[('Scale',scalePipe,scale),('One Hot',OneHotEncoder(),one_hot)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = {'C':[0.1,0.5,1,5,10,50]}\n",
    "Grid_Search = GridSearchCV(SVR(),Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_Ahead = dayAhead.to_frame()\n",
    "Day_Ahead['Day of Month'] = Day_Ahead.index.get_level_values('date').day\n",
    "Day_Ahead['Month'] = Day_Ahead.index.get_level_values('date').month\n",
    "Day_Ahead['Year'] = Day_Ahead.index.get_level_values('date').year\n",
    "Day_Ahead['Day of Week'] = Day_Ahead.index.get_level_values('date').weekday\n",
    "DOW = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "Day_Ahead['Day Of Week String'] = Day_Ahead['Day of Week'].map(DOW)\n",
    "Day_Ahead['Month Name'] = Day_Ahead['Month'].map(MonthToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_Ahead_Weather = Day_Ahead.reset_index().merge(weather,left_on='date',right_on='date').set_index(['prop','date']).loc['mean']\n",
    "Day_Ahead_All = Day_Ahead_Weather.reset_index().merge(capacity,left_on=['Month','Year'],right_on=['Month','Year']).set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_Ahead_All.to_pickle('dayahead_combined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = Day_Ahead_All['total']\n",
    "X2 = Day_Ahead_All.drop(['total','Day of Month','Month','Year','Day of Week'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if random sampling works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates = list(set(list(X.index)))\n",
    "Dates.sort()\n",
    "Dates[::10]\n",
    "X3_test = X.loc[Dates[::10]]\n",
    "X3_train = X.drop(Dates[::10],axis=0)\n",
    "y3_test = y.loc[Dates[::10]]\n",
    "y3_train = y.drop(Dates[::10],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = Pipeline([('column',Column_Transformer),('grid',Grid_Search)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates = list(set(list(X2.index)))\n",
    "Dates.sort()\n",
    "Dates[::10]\n",
    "X4_test = X2.loc[Dates[::10]]\n",
    "X4_train = X2.drop(Dates[::10],axis=0)\n",
    "y4_test = y2.loc[Dates[::10]]\n",
    "y4_train = y2.drop(Dates[::10],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = Pipeline([('column',Column_Transformer),('grid',Grid_Search)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtract drift, periodicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn import base\n",
    "class FourierTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['Julian_Day'] = X.index.to_julian_date()\n",
    "        X['sin1'] = np.sin(2*math.pi*X['Julian_Day'].astype(int)/365.25)\n",
    "        X['cos1'] = np.cos(2*math.pi*X['Julian_Day'].astype(int)/365.25)\n",
    "        X['sin2'] = np.sin(2*math.pi*X['Julian_Day'].astype(int)/7)\n",
    "        X['cos2'] = np.cos(2*math.pi*X['Julian_Day'].astype(int)/7)\n",
    "        X['sin3'] = np.sin(2*math.pi*X['Julian_Day'].astype(int)/182.625)\n",
    "        X['cos3'] = np.cos(2*math.pi*X['Julian_Day'].astype(int)/182.625)\n",
    "        X['sin4'] = np.sin(2*math.pi*X['Julian_Day'].astype(int)/3.5)\n",
    "        X['cos4'] = np.cos(2*math.pi*X['Julian_Day'].astype(int)/3.5)\n",
    "        # Return an array with the same number of rows as X and one\n",
    "        # column for each in self.col_names\n",
    "        return X[['sin1','cos1','sin2','cos2','sin3','cos3','sin4','cos4']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Composite(base.BaseEstimator, base.RegressorMixin):\n",
    "  def __init__(self, linear,nonlinear):\n",
    "    self.linear = linear\n",
    "    self.nonlinear = nonlinear\n",
    "    self.fourier = FourierTransformer()\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    X2 = self.fourier.fit_transform(X)\n",
    "    self.linear.fit(X2,y)\n",
    "    res = np.asarray(y) - np.asarray(self.linear.predict(X2))\n",
    "    self.nonlinear.fit(X,res)\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    # make predictions \n",
    "    X2 = self.fourier.transform(X)\n",
    "    pred = np.asarray(self.linear.predict(X2))+np.asarray(self.nonlinear.predict(X))\n",
    "    return list(pred)\n",
    "\n",
    "  def score(self, X, y):\n",
    "    pred = self.predict(X)\n",
    "    ave_y = np.mean(y)\n",
    "    y = np.asarray(y)\n",
    "    r2 = 1-np.sum((y-pred)**2)/np.sum((y-ave_y)**2)\n",
    "    # custom score implementation\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Composite(linear=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001),\n",
       "          nonlinear=Pipeline(memory=None,\n",
       "                             steps=[('column',\n",
       "                                     ColumnTransformer(n_jobs=None,\n",
       "                                                       remainder='drop',\n",
       "                                                       sparse_threshold=0.3,\n",
       "                                                       transformer_weights=None,\n",
       "                                                       transformers=[('Scale',\n",
       "                                                                      Pipeline(memory=None,\n",
       "                                                                               steps=[('impute',\n",
       "                                                                                       KNNImputer(...\n",
       "                                                                       'Capacity', ...]),\n",
       "                                                                     ('One Hot',\n",
       "                                                                      OneHotEncoder(categories='auto',\n",
       "                                                                                    drop=None,\n",
       "                                                                                    dtype=<class 'numpy.float64'>,\n",
       "                                                                                    handle_unknown='error',\n",
       "                                                                                    sparse=True),\n",
       "                                                                      ['region',\n",
       "                                                                       'Day Of '\n",
       "                                                                       'Week '\n",
       "                                                                       'String',\n",
       "                                                                       'Month '\n",
       "                                                                       'Name'])],\n",
       "                                                       verbose=False)),\n",
       "                                    ('SVR',\n",
       "                                     SVR(C=50, cache_size=200, coef0=0.0,\n",
       "                                         degree=3, epsilon=0.1, gamma='scale',\n",
       "                                         kernel='rbf', max_iter=-1,\n",
       "                                         shrinking=True, tol=0.001,\n",
       "                                         verbose=False))],\n",
       "                             verbose=False))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVR\n",
    "Dates = list(set(list(X.index)))\n",
    "Dates.sort()\n",
    "Dates[::10]\n",
    "X3_test = X.loc[Dates[::10]]\n",
    "X3_train = X.drop(Dates[::10],axis=0)\n",
    "y3_test = y.loc[Dates[::10]]\n",
    "y3_train = y.drop(Dates[::10],axis=0)\n",
    "pipe3 = Pipeline([('column',Column_Transformer),('SVR',SVR(C=50))])\n",
    "composite = Composite(Ridge(),pipe3)\n",
    "composite.fit(X3_train,y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32801700166186054"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composite.score(X3_test,y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/data3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Composite(linear=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001),\n",
       "          nonlinear=Pipeline(memory=None,\n",
       "                             steps=[('column',\n",
       "                                     ColumnTransformer(n_jobs=None,\n",
       "                                                       remainder='drop',\n",
       "                                                       sparse_threshold=0.3,\n",
       "                                                       transformer_weights=None,\n",
       "                                                       transformers=[('Scale',\n",
       "                                                                      Pipeline(memory=None,\n",
       "                                                                               steps=[('impute',\n",
       "                                                                                       KNNImputer(...\n",
       "                                                                       'Capacity', ...]),\n",
       "                                                                     ('One Hot',\n",
       "                                                                      OneHotEncoder(categories='auto',\n",
       "                                                                                    drop=None,\n",
       "                                                                                    dtype=<class 'numpy.float64'>,\n",
       "                                                                                    handle_unknown='error',\n",
       "                                                                                    sparse=True),\n",
       "                                                                      ['region',\n",
       "                                                                       'Day Of '\n",
       "                                                                       'Week '\n",
       "                                                                       'String',\n",
       "                                                                       'Month '\n",
       "                                                                       'Name'])],\n",
       "                                                       verbose=False)),\n",
       "                                    ('SVR',\n",
       "                                     SVR(C=50, cache_size=200, coef0=0.0,\n",
       "                                         degree=3, epsilon=0.1, gamma='scale',\n",
       "                                         kernel='rbf', max_iter=-1,\n",
       "                                         shrinking=True, tol=0.001,\n",
       "                                         verbose=False))],\n",
       "                             verbose=False))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVR\n",
    "Dates = list(set(list(X2.index)))\n",
    "Dates.sort()\n",
    "Dates[::10]\n",
    "X4_test = X2.loc[Dates[::10]]\n",
    "X4_train = X2.drop(Dates[::10],axis=0)\n",
    "y4_test = y2.loc[Dates[::10]]\n",
    "y4_train = y2.drop(Dates[::10],axis=0)\n",
    "pipe4 = Pipeline([('column',Column_Transformer),('SVR',SVR(C=50))])\n",
    "composite2 = Composite(Ridge(),pipe4)\n",
    "composite2.fit(X4_train,y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5843980967711122"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composite2.score(X4_test,y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dayahead_model_Fourier.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "dump(composite,'realtime_model_Fourier.pkl')\n",
    "dump(composite2,'dayahead_model_Fourier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
